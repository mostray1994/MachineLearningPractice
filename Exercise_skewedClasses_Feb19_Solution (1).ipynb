{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skewed Classes\n",
    "\n",
    "In this exercise, we use digits data set of Scikit-learn. Run the code below read the description of the data set and show a sample. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n",
      "Optical Recognition of Handwritten Digits Data Set\n",
      "===================================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "References\n",
      "----------\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118d4aac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0H8AyqmA3mgPYnMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1190e59e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DigitsData=load_digits()\n",
    "print(DigitsData.keys()) \n",
    "print(DigitsData.DESCR) #read description of the dataset\n",
    "\n",
    "#plot one of the images in the data\n",
    "plt.gray() \n",
    "plt.matshow(DigitsData.images[1]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is to build classfiers that identify digit 9. For this purpose, do the following:\n",
    "\n",
    "1) Define the target value to be equal to 1 only for digit 9\n",
    "\n",
    "You can use: y= (DigitsData.target == 9)\n",
    "\n",
    "\n",
    "- Find how many times y is equal to True and how many times it is equal to False\n",
    "\n",
    "You can use: print(sum(y==True)); print(sum(y==False))\n",
    "\n",
    "\n",
    "COMMENT: what do you observe? Is the dataset for this classification problem balanced or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y samples are: [False False False ..., False  True False]\n",
      "Number of examples where y=True is: 180\n",
      "Number of examples where y=False is: 1617\n",
      "COMMENT: Number of False examples are much more than the number of True examples. This is an imbalanced data.\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "y= (DigitsData.target == 9)\n",
    "\n",
    "print(\"y samples are:\", y)\n",
    "print(\"Number of examples where y=True is:\" , sum(y==True))\n",
    "print(\"Number of examples where y=False is:\", sum(y==False))\n",
    "\n",
    "\n",
    "print(\"COMMENT: Number of False examples are much more than the number of True examples. This is an imbalanced data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Find the accuracy of a dummy classifier that always selects the majority class. Use the DigitsData.data as features and y (defined above) as the response, then train_test_split to get training and test data.\n",
    "\n",
    "You can use:\n",
    "\n",
    "      X_train, X_test, Y_train, Y_test= train_test_split(DigitsData.data, y, random_state= 0)\n",
    "      from sklearn.dummy import DummyClassifier\n",
    "      dummy_majority=DummyClassifier(strategy='most_frequent').fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of dummy classifier is: 0.895555555556\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(DigitsData.data, y, random_state= 0)\n",
    "\n",
    "#Dummy Classifier\n",
    "dummy_majority=DummyClassifier(strategy='most_frequent').fit(X_train, Y_train)\n",
    "print(\"The accuracy of dummy classifier is:\", dummy_majority.score(X_test,Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Build QDA classifier. Find accuracy, confusion matrix, precision, and recall\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of QDA is: 0.762222222222\n",
      "Confusion matrix of QDA is: \n",
      " [[297 106]\n",
      " [  1  46]]\n",
      "precision score of QDA is : 0.302631578947\n",
      "recall score of QDA is : 0.978723404255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "#QDA \n",
    "FittedQDA=QuadraticDiscriminantAnalysis().fit(X_train,Y_train)\n",
    "print(\"the accuracy of QDA is:\", FittedQDA.score(X_test,Y_test))\n",
    "\n",
    "PredictedOutput_QDA=FittedQDA.predict(X_test)\n",
    "\n",
    "confusionQDA=confusion_matrix(Y_test,PredictedOutput_QDA)\n",
    "print(\"Confusion matrix of QDA is: \\n\", confusionQDA) #\\n is for enter\n",
    "\n",
    "print(\"precision score of QDA is :\", precision_score(Y_test,PredictedOutput_QDA))\n",
    "print(\"recall score of QDA is :\", recall_score(Y_test,PredictedOutput_QDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Build LDA classifier. Find accuracy, confusion matrix, precision, and recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of LDA is: 0.964444444444\n",
      "Confusion matrix of LDA is: \n",
      " [[394   9]\n",
      " [  7  40]]\n",
      "precision score of LDA is : 0.816326530612\n",
      "recall score of LDA is : 0.851063829787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "\n",
    "#LDA\n",
    "LDAmodelFitted = LinearDiscriminantAnalysis().fit(X_train, Y_train)\n",
    "\n",
    "print(\"the accuracy of LDA is:\", LDAmodelFitted.score(X_test,Y_test))\n",
    "\n",
    "PredictedOutput_LDA=LDAmodelFitted.predict(X_test)\n",
    "\n",
    "confusionLDA=confusion_matrix(Y_test,PredictedOutput_LDA)\n",
    "print(\"Confusion matrix of LDA is: \\n\", confusionLDA) #\\n is for enter\n",
    "\n",
    "print(\"precision score of LDA is :\", precision_score(Y_test,PredictedOutput_LDA))\n",
    "print(\"recall score of LDA is :\", recall_score(Y_test,PredictedOutput_LDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "\n",
    "Find the 5-fold cross validation score for logistic regression (with default regularization C=1) that classifies the ten classes of the digits data. Comment on your result. \n",
    "What is the average accuracy of the 5 folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold cross validation scores are: [ 0.92307692  0.88121547  0.94986072  0.95798319  0.89295775]\n",
      "average of the 5 fold cross validation scores is: 0.921018811336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#5-fold cross valudation\n",
    "logRegModel=LogisticRegression(C=1)\n",
    "scores = cross_val_score(logRegModel, DigitsData.data, DigitsData.target, cv=5)\n",
    "print(\"5 fold cross validation scores are:\", scores)\n",
    "\n",
    "print(\"average of the 5 fold cross validation scores is:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
