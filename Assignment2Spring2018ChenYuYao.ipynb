{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<h2>INFSCI 2915 Foundations- Machine Learning - Spring 2018 </h2>\n",
    "<h1 style=\"font-size: 250%;\">Assignment #2</h1>\n",
    "<h3>Issued Monday, 2/26/2018; Due Monday, 11:59pm, 3/12/2018</h3>\n",
    "<h3>Total points: 100 </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Type in your information in the double quotes\n",
    "firstName = \"Yuyao\"\n",
    "lastName = \"Chen\"\n",
    "pittID = \"YUC107\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #1. Train Test Split [20 points]</h3> \n",
    "In this part, you should download **\"Iris dataset\"**. <br>\n",
    "Use a code below to download the  dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset=load_iris()\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-1. </h4> Split iris dataset into training and test datasets. (use train_test_split function and random_state=0)\n",
    "\n",
    "- Report the shape of each (training and test) datasets. What is the proportion of each set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------original shape of dataset-------\n",
      "(150, 4)\n",
      "(150,)\n",
      "-------shape of training dataset-------\n",
      "(112, 4)\n",
      "(112,)\n",
      "-------shape of test dataset-------\n",
      "(38, 4)\n",
      "(38,)\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"-------original shape of dataset-------\")\n",
    "print(dataset.data.shape)\n",
    "print(dataset.target.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data,dataset.target,random_state=0)\n",
    "print(\"-------shape of training dataset-------\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"-------shape of test dataset-------\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 1-1\n",
    "the shapes of training dataset and test dataset above, the proportion of training dataset is 75%, the proportion of test dataset is 25%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-2. </h4>  Split iris dataset into training and test datasets. Make the proportion of training dataset 60% (use train_test_split function and random_state=0)\n",
    " \n",
    "\n",
    "- Report the shape of each (training and test) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------shape of training dataset-------\n",
      "(90, 4)\n",
      "(90,)\n",
      "-------shape of test dataset-------\n",
      "(60, 4)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data,dataset.target,test_size=0.4,random_state=0)\n",
    "print(\"-------shape of training dataset-------\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"-------shape of test dataset-------\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 1-2\n",
    "the shapes of training dataset and test dataset above, shape of training dataset is 90 examples, shape of test dataset is 60 examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-3. </h4>  Split iris dataset into training and test datasets. Make the proportion of test dataset 33.3% (use train_test_split function and random_state=0)\n",
    "  \n",
    "\n",
    "- Report the shape of each (training and test) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------shape of training dataset-------\n",
      "(100, 4)\n",
      "(100,)\n",
      "-------shape of test dataset-------\n",
      "(50, 4)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data,dataset.target,test_size=0.333,random_state=0)\n",
    "print(\"-------shape of training dataset-------\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"-------shape of test dataset-------\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 1-3\n",
    "the shapes of training dataset and test dataset above, shape of training dataset is 100 examples, shape of test dataset is 50 examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-4. Random State </h4> \n",
    "Split iris dataset into training and test datasets, Use different Random State values (0,  10, 253, 1000, 0 and 10) \n",
    "\n",
    "- Analyze the shape and values of the train and test datasets  generated from different Random State values (you can use descriptive statistics) \n",
    "\n",
    "- What happens if you do not specify Random State? \n",
    "\n",
    "- What is a purpose of using Random State? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state:  0\n",
      "(112, 4)\n",
      "(339,)\n",
      "(38, 4)\n",
      "(167,)\n",
      "                0           1           2           3\n",
      "count  112.000000  112.000000  112.000000  112.000000\n",
      "mean     5.886607    3.051786    3.796429    1.222321\n",
      "std      0.871314    0.436196    1.800697    0.782662\n",
      "min      4.300000    2.000000    1.100000    0.100000\n",
      "25%      5.100000    2.800000    1.575000    0.300000\n",
      "50%      5.800000    3.000000    4.250000    1.300000\n",
      "75%      6.500000    3.300000    5.200000    1.900000\n",
      "max      7.900000    4.400000    6.900000    2.500000\n",
      "random state:  10\n",
      "(112, 4)\n",
      "(339,)\n",
      "(38, 4)\n",
      "(167,)\n",
      "                0           1           2           3\n",
      "count  112.000000  112.000000  112.000000  112.000000\n",
      "mean     5.840179    3.075000    3.716071    1.187500\n",
      "std      0.839397    0.441231    1.794162    0.774611\n",
      "min      4.300000    2.200000    1.000000    0.100000\n",
      "25%      5.100000    2.800000    1.600000    0.300000\n",
      "50%      5.750000    3.000000    4.200000    1.300000\n",
      "75%      6.400000    3.400000    5.100000    1.800000\n",
      "max      7.900000    4.400000    6.900000    2.500000\n",
      "random state:  253\n",
      "(112, 4)\n",
      "(339,)\n",
      "(38, 4)\n",
      "(167,)\n",
      "                0           1          2           3\n",
      "count  112.000000  112.000000  112.00000  112.000000\n",
      "mean     5.803571    3.066071    3.62500    1.135714\n",
      "std      0.836545    0.428396    1.73727    0.744815\n",
      "min      4.300000    2.200000    1.10000    0.100000\n",
      "25%      5.100000    2.800000    1.50000    0.300000\n",
      "50%      5.700000    3.000000    4.20000    1.300000\n",
      "75%      6.400000    3.225000    5.00000    1.800000\n",
      "max      7.900000    4.400000    6.70000    2.500000\n",
      "random state:  1000\n",
      "(112, 4)\n",
      "(339,)\n",
      "(38, 4)\n",
      "(167,)\n",
      "                0           1           2           3\n",
      "count  112.000000  112.000000  112.000000  112.000000\n",
      "mean     5.861607    3.075000    3.747321    1.195536\n",
      "std      0.866311    0.418384    1.823123    0.776152\n",
      "min      4.300000    2.300000    1.000000    0.100000\n",
      "25%      5.100000    2.800000    1.500000    0.300000\n",
      "50%      5.800000    3.000000    4.400000    1.300000\n",
      "75%      6.500000    3.400000    5.100000    1.825000\n",
      "max      7.900000    4.200000    6.900000    2.500000\n"
     ]
    }
   ],
   "source": [
    "rs = [0,10,253,1000]\n",
    "for index in range(len(rs)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset.data,dataset.target,random_state=rs[index])\n",
    "    print(\"random state: \",rs[index])\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_test.shape)\n",
    "    df = pd.DataFrame(X_train)\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 1-4\n",
    "- it results in same proportion but different values with drfferent random state.\n",
    "- if I don't specify random state, the default is none. If None, the random number generator is the RandomState instance used by np.random.\n",
    "- the purpose of using Random State is for reproducibility, which means I can get the same result when I specify same random state number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #1-5. Optional (Extra Points) </h4> \n",
    "\n",
    "\n",
    "Write a python function that takes the dataset X  (matrix) and Y (numpy array) as an input and returns two non-overlapping datasets: the training and testing data, such that every entry to training set should be selected randomly. The proportion of the training and testing data should be 75%(training)/25%(test). Test your function using the synthetic dataset below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0\n",
      " 1 0 1 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.randint(2, size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>3000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>400</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>600</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>700</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>800</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>900</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2   X3    X4  Y\n",
       "0   0   0    0     0  0\n",
       "1   1  10  100  1000  0\n",
       "2   2  20  200  2000  0\n",
       "3   3  30  300  3000  1\n",
       "4   4  40  400  4000  0\n",
       "5   5  50  500  5000  1\n",
       "6   6  60  600  6000  0\n",
       "7   7  70  700  7000  0\n",
       "8   8  80  800  8000  0\n",
       "9   9  90  900  9000  0"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "X = np.stack((np.arange(100), 10*np.array(np.arange(100)),100*np.array(np.arange(100)),1000*np.array(np.arange(100))), axis=-1)\n",
    "Y = np.random.randint(2, size=100)\n",
    "df = pd.DataFrame(np.concatenate((X,Y[:,None]),axis=1), columns = (\"X1\",\"X2\",\"X3\",\"X4\", \"Y\"))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>340</td>\n",
       "      <td>3400</td>\n",
       "      <td>34000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>720</td>\n",
       "      <td>7200</td>\n",
       "      <td>72000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>370</td>\n",
       "      <td>3700</td>\n",
       "      <td>37000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>860</td>\n",
       "      <td>8600</td>\n",
       "      <td>86000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>640</td>\n",
       "      <td>6400</td>\n",
       "      <td>64000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>800</td>\n",
       "      <td>8000</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>630</td>\n",
       "      <td>6300</td>\n",
       "      <td>63000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>900</td>\n",
       "      <td>9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>190</td>\n",
       "      <td>1900</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>410</td>\n",
       "      <td>4100</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>930</td>\n",
       "      <td>9300</td>\n",
       "      <td>93000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>460</td>\n",
       "      <td>4600</td>\n",
       "      <td>46000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>480</td>\n",
       "      <td>4800</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>880</td>\n",
       "      <td>8800</td>\n",
       "      <td>88000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>600</td>\n",
       "      <td>6000</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>440</td>\n",
       "      <td>4400</td>\n",
       "      <td>44000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>430</td>\n",
       "      <td>4300</td>\n",
       "      <td>43000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>130</td>\n",
       "      <td>1300</td>\n",
       "      <td>13000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>390</td>\n",
       "      <td>3900</td>\n",
       "      <td>39000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>850</td>\n",
       "      <td>8500</td>\n",
       "      <td>85000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>170</td>\n",
       "      <td>1700</td>\n",
       "      <td>17000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>470</td>\n",
       "      <td>4700</td>\n",
       "      <td>47000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>280</td>\n",
       "      <td>2800</td>\n",
       "      <td>28000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>660</td>\n",
       "      <td>6600</td>\n",
       "      <td>66000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>770</td>\n",
       "      <td>7700</td>\n",
       "      <td>77000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>360</td>\n",
       "      <td>3600</td>\n",
       "      <td>36000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>380</td>\n",
       "      <td>3800</td>\n",
       "      <td>38000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>990</td>\n",
       "      <td>9900</td>\n",
       "      <td>99000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>580</td>\n",
       "      <td>5800</td>\n",
       "      <td>58000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>800</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>330</td>\n",
       "      <td>3300</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>900</td>\n",
       "      <td>9000</td>\n",
       "      <td>90000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>690</td>\n",
       "      <td>6900</td>\n",
       "      <td>69000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>950</td>\n",
       "      <td>9500</td>\n",
       "      <td>95000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>3000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>520</td>\n",
       "      <td>5200</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>620</td>\n",
       "      <td>6200</td>\n",
       "      <td>62000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>210</td>\n",
       "      <td>2100</td>\n",
       "      <td>21000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>2000</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>610</td>\n",
       "      <td>6100</td>\n",
       "      <td>61000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>670</td>\n",
       "      <td>6700</td>\n",
       "      <td>67000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>590</td>\n",
       "      <td>5900</td>\n",
       "      <td>59000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>450</td>\n",
       "      <td>4500</td>\n",
       "      <td>45000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>320</td>\n",
       "      <td>3200</td>\n",
       "      <td>32000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>310</td>\n",
       "      <td>3100</td>\n",
       "      <td>31000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>350</td>\n",
       "      <td>3500</td>\n",
       "      <td>35000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>700</td>\n",
       "      <td>7000</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>980</td>\n",
       "      <td>9800</td>\n",
       "      <td>98000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>540</td>\n",
       "      <td>5400</td>\n",
       "      <td>54000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>220</td>\n",
       "      <td>2200</td>\n",
       "      <td>22000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>830</td>\n",
       "      <td>8300</td>\n",
       "      <td>83000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>240</td>\n",
       "      <td>2400</td>\n",
       "      <td>24000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>230</td>\n",
       "      <td>2300</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>840</td>\n",
       "      <td>8400</td>\n",
       "      <td>84000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>1500</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2    X3     X4  Y\n",
       "34  34  340  3400  34000  1\n",
       "2    2   20   200   2000  0\n",
       "72  72  720  7200  72000  0\n",
       "37  37  370  3700  37000  1\n",
       "86  86  860  8600  86000  0\n",
       "64  64  640  6400  64000  0\n",
       "80  80  800  8000  80000  0\n",
       "63  63  630  6300  63000  0\n",
       "9    9   90   900   9000  0\n",
       "19  19  190  1900  19000  0\n",
       "41  41  410  4100  41000  1\n",
       "10  10  100  1000  10000  0\n",
       "93  93  930  9300  93000  1\n",
       "46  46  460  4600  46000  1\n",
       "48  48  480  4800  48000  1\n",
       "88  88  880  8800  88000  0\n",
       "60  60  600  6000  60000  0\n",
       "44  44  440  4400  44000  0\n",
       "43  43  430  4300  43000  1\n",
       "13  13  130  1300  13000  0\n",
       "39  39  390  3900  39000  1\n",
       "85  85  850  8500  85000  0\n",
       "17  17  170  1700  17000  1\n",
       "47  47  470  4700  47000  0\n",
       "28  28  280  2800  28000  1\n",
       "66  66  660  6600  66000  1\n",
       "5    5   50   500   5000  1\n",
       "77  77  770  7700  77000  0\n",
       "36  36  360  3600  36000  0\n",
       "38  38  380  3800  38000  0\n",
       "..  ..  ...   ...    ... ..\n",
       "99  99  990  9900  99000  0\n",
       "58  58  580  5800  58000  0\n",
       "8    8   80   800   8000  0\n",
       "33  33  330  3300  33000  0\n",
       "90  90  900  9000  90000  0\n",
       "69  69  690  6900  69000  1\n",
       "95  95  950  9500  95000  0\n",
       "3    3   30   300   3000  1\n",
       "0    0    0     0      0  0\n",
       "52  52  520  5200  52000  0\n",
       "62  62  620  6200  62000  1\n",
       "21  21  210  2100  21000  1\n",
       "50  50  500  5000  50000  1\n",
       "20  20  200  2000  20000  1\n",
       "61  61  610  6100  61000  0\n",
       "67  67  670  6700  67000  1\n",
       "59  59  590  5900  59000  1\n",
       "45  45  450  4500  45000  1\n",
       "32  32  320  3200  32000  1\n",
       "31  31  310  3100  31000  1\n",
       "35  35  350  3500  35000  0\n",
       "70  70  700  7000  70000  0\n",
       "98  98  980  9800  98000  1\n",
       "54  54  540  5400  54000  0\n",
       "22  22  220  2200  22000  0\n",
       "83  83  830  8300  83000  0\n",
       "24  24  240  2400  24000  1\n",
       "23  23  230  2300  23000  0\n",
       "84  84  840  8400  84000  0\n",
       "15  15  150  1500  15000  1\n",
       "\n",
       "[80 rows x 5 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "train=df.sample(frac=0.8,random_state=200)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>600</td>\n",
       "      <td>6000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>700</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>110</td>\n",
       "      <td>1100</td>\n",
       "      <td>11000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>140</td>\n",
       "      <td>1400</td>\n",
       "      <td>14000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>1600</td>\n",
       "      <td>16000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>260</td>\n",
       "      <td>2600</td>\n",
       "      <td>26000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>270</td>\n",
       "      <td>2700</td>\n",
       "      <td>27000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>420</td>\n",
       "      <td>4200</td>\n",
       "      <td>42000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>510</td>\n",
       "      <td>5100</td>\n",
       "      <td>51000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>550</td>\n",
       "      <td>5500</td>\n",
       "      <td>55000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>560</td>\n",
       "      <td>5600</td>\n",
       "      <td>56000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>570</td>\n",
       "      <td>5700</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>680</td>\n",
       "      <td>6800</td>\n",
       "      <td>68000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>730</td>\n",
       "      <td>7300</td>\n",
       "      <td>73000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>760</td>\n",
       "      <td>7600</td>\n",
       "      <td>76000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>790</td>\n",
       "      <td>7900</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>890</td>\n",
       "      <td>8900</td>\n",
       "      <td>89000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>920</td>\n",
       "      <td>9200</td>\n",
       "      <td>92000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>960</td>\n",
       "      <td>9600</td>\n",
       "      <td>96000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2    X3     X4  Y\n",
       "1    1   10   100   1000  0\n",
       "6    6   60   600   6000  0\n",
       "7    7   70   700   7000  0\n",
       "11  11  110  1100  11000  0\n",
       "14  14  140  1400  14000  1\n",
       "16  16  160  1600  16000  0\n",
       "26  26  260  2600  26000  1\n",
       "27  27  270  2700  27000  0\n",
       "42  42  420  4200  42000  1\n",
       "51  51  510  5100  51000  1\n",
       "55  55  550  5500  55000  1\n",
       "56  56  560  5600  56000  0\n",
       "57  57  570  5700  57000  0\n",
       "68  68  680  6800  68000  0\n",
       "73  73  730  7300  73000  1\n",
       "76  76  760  7600  76000  1\n",
       "79  79  790  7900  79000  0\n",
       "89  89  890  8900  89000  0\n",
       "92  92  920  9200  92000  0\n",
       "96  96  960  9600  96000  0"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=df.drop(train.index)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Problem #2. Feature Selection  [10 points] </h3>  <br>\n",
    "In this part, you should download and analyze **\"Boston House Prices\" ** dataset **with only 4 features**. <br>\n",
    "(use code below to download  and change dataset)\n",
    "\n",
    "- Find the best two features using forward and backward selection to the Boston House Prices\" dataset with only 4 features ('CHAS','RM','TAX', 'LSTAT'), use a linear regression model to find a best subset of features.\n",
    "- Comment your choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.       5.605  330.      18.46 ] 18.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "dataset = load_boston()\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    " #print(dataset.keys())\n",
    "\n",
    "# Data preprocessing\n",
    "new_data= pd.DataFrame(dataset.data, columns=dataset.feature_names)[['CHAS','RM','TAX', 'LSTAT']]\n",
    "#new_data['target']=dataset.target\n",
    "#print(new_data)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(new_data.values,dataset.target,random_state=0)\n",
    "print(X_train[0],Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 of regr1:  0.0489763879303\n",
      "R2 of regr2:  0.467900054314\n",
      "R2 of regr3:  0.0952371450838\n",
      "R2 of regr4:  0.457639361556\n"
     ]
    }
   ],
   "source": [
    "CHAS_train = X_train[:,:1]\n",
    "RM_train = X_train[:,1:2]\n",
    "TAX_train = X_train[:,2:3]\n",
    "LSTAT_train = X_train[:,3:]\n",
    "CHAS_test = X_test[:,:1]\n",
    "RM_test = X_test[:,1:2]\n",
    "TAX_test = X_test[:,2:3]\n",
    "LSTAT_test = X_test[:,3:]\n",
    "regr1 = LinearRegression().fit(CHAS_train,Y_train)\n",
    "regr2 = LinearRegression().fit(RM_train,Y_train)\n",
    "regr3 = LinearRegression().fit(TAX_train,Y_train)\n",
    "regr4 = LinearRegression().fit(LSTAT_train,Y_train)\n",
    "print(\"R2 of regr1: \",regr1.score(CHAS_test,Y_test))\n",
    "print(\"R2 of regr2: \",regr2.score(RM_test,Y_test))\n",
    "print(\"R2 of regr3: \",regr3.score(TAX_test,Y_test))\n",
    "print(\"R2 of regr4: \",regr4.score(LSTAT_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 of regr5:  0.489183148248\n",
      "R2 of regr6:  0.435203893137\n",
      "R2 of regr7:  0.569244541584\n"
     ]
    }
   ],
   "source": [
    "regr5 = LinearRegression().fit(np.concatenate((RM_train,CHAS_train),axis=1),Y_train)\n",
    "regr6 = LinearRegression().fit(np.concatenate((RM_train,TAX_train),axis=1),Y_train)\n",
    "regr7 = LinearRegression().fit(np.concatenate((RM_train,LSTAT_train),axis=1),Y_train)\n",
    "print(\"R2 of regr5: \",regr5.score(np.concatenate((RM_test,CHAS_test),axis=1),Y_test))\n",
    "print(\"R2 of regr6: \",regr6.score(np.concatenate((RM_test,TAX_test),axis=1),Y_test))\n",
    "print(\"R2 of regr7: \",regr7.score(np.concatenate((RM_test,LSTAT_test),axis=1),Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P values:\n",
      " CHAS      1.900085e-05\n",
      "RM       5.327145e-218\n",
      "TAX       1.657945e-04\n",
      "LSTAT     1.757948e-38\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "model = smf.OLS(dataset.target,new_data)\n",
    "ml = model.fit()\n",
    "print(\"P values:\\n\",ml.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P values:\n",
      " CHAS      1.886145e-05\n",
      "RM       9.232978e-259\n",
      "LSTAT     7.363807e-74\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_data2 = pd.DataFrame(dataset.data, columns=dataset.feature_names)[['CHAS','RM','LSTAT']]\n",
    "model2 = smf.OLS(dataset.target,new_data2)\n",
    "ml2 = model2.fit()\n",
    "print(\"P values:\\n\",ml2.pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 2\n",
    "- in forward selection part, we add to the null model the feature that results in lowest RSS, bigger R2 means smaller RSS, so we choose RM first. and then I combine the RM with the other feature, LSTAT results in lowset R2, so I choose LSTAT then.    \n",
    "- in backward selection part, the feature with the largest p value is removed, so I remove TAX first. and than I choose CHAS because it has the largest p value  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #3. Qualitative Variables  [10 points] </h3>\n",
    "\n",
    "In this part, you should download and analyze **\"Boston House Prices\"** dataset. <br>\n",
    "Use a code below to download the  dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR'])\n",
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import sklearn.cross_validation\n",
    "dataset = load_boston()\n",
    "print(dataset.keys())\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #3-1. </h4> Follow steps to answer questions.\n",
    "> *Use train_test_split() with the option \"random_state=0\".\n",
    "\n",
    "- Identify qualitative feature in the dataset (a feature with dummy variable). What is an abbreviation for the qualitative feature? (What is a definition of that  abbreviation ?)\n",
    "\n",
    "- Fit a linear regression model with qualitative variable feature only. Report intercept and coefficient.  \n",
    "\n",
    "- What can you infer about the qualitative feature from the coefficient? (Hint check lecture:  \"Regression with Qualitative Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>392.52</td>\n",
       "      <td>20.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.50</td>\n",
       "      <td>15.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.02</td>\n",
       "      <td>10.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.05393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.935</td>\n",
       "      <td>29.3</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.85</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.75</td>\n",
       "      <td>14.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>288.99</td>\n",
       "      <td>11.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.25179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.570</td>\n",
       "      <td>98.1</td>\n",
       "      <td>3.7979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.57</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.85204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.965</td>\n",
       "      <td>89.2</td>\n",
       "      <td>4.0123</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>392.53</td>\n",
       "      <td>13.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.98843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.54</td>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.75026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.924</td>\n",
       "      <td>94.1</td>\n",
       "      <td>4.3996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.33</td>\n",
       "      <td>16.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>303.42</td>\n",
       "      <td>16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.67191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>90.3</td>\n",
       "      <td>4.6820</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.88</td>\n",
       "      <td>14.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.95577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.047</td>\n",
       "      <td>88.8</td>\n",
       "      <td>4.4534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>306.38</td>\n",
       "      <td>17.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.77299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.495</td>\n",
       "      <td>94.4</td>\n",
       "      <td>4.4547</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>387.94</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.674</td>\n",
       "      <td>87.3</td>\n",
       "      <td>4.2390</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.23</td>\n",
       "      <td>11.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4.87141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.484</td>\n",
       "      <td>93.6</td>\n",
       "      <td>2.3053</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.21</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>10.23300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.185</td>\n",
       "      <td>96.7</td>\n",
       "      <td>2.1705</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>379.70</td>\n",
       "      <td>18.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>14.33370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.229</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.9512</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>383.32</td>\n",
       "      <td>13.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5.82401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.242</td>\n",
       "      <td>64.7</td>\n",
       "      <td>3.4242</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>10.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5.70818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.750</td>\n",
       "      <td>74.9</td>\n",
       "      <td>3.3317</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>393.07</td>\n",
       "      <td>7.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>5.73116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>7.061</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.4106</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.28</td>\n",
       "      <td>7.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2.81838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>5.762</td>\n",
       "      <td>40.3</td>\n",
       "      <td>4.0983</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.92</td>\n",
       "      <td>10.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2.37857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.871</td>\n",
       "      <td>41.9</td>\n",
       "      <td>3.7240</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>370.73</td>\n",
       "      <td>13.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3.67367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.312</td>\n",
       "      <td>51.9</td>\n",
       "      <td>3.9917</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.62</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>5.69175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.114</td>\n",
       "      <td>79.8</td>\n",
       "      <td>3.5459</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.68</td>\n",
       "      <td>14.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4.83567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.905</td>\n",
       "      <td>53.2</td>\n",
       "      <td>3.1523</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.22</td>\n",
       "      <td>11.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.15086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.454</td>\n",
       "      <td>92.7</td>\n",
       "      <td>1.8209</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>395.09</td>\n",
       "      <td>18.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.18337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.414</td>\n",
       "      <td>98.3</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>344.05</td>\n",
       "      <td>23.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.20746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.093</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.8226</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>318.43</td>\n",
       "      <td>29.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.11132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>83.5</td>\n",
       "      <td>2.1099</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.17331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.707</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.27957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.926</td>\n",
       "      <td>42.6</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.17899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.670</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>393.29</td>\n",
       "      <td>17.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.28960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.390</td>\n",
       "      <td>72.9</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.26838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.794</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.8927</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.23912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.019</td>\n",
       "      <td>65.3</td>\n",
       "      <td>2.4091</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.17783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.569</td>\n",
       "      <td>73.5</td>\n",
       "      <td>2.3999</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>395.77</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0     0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n",
       "1     0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671   2.0  242.0   \n",
       "2     0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671   2.0  242.0   \n",
       "3     0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622   3.0  222.0   \n",
       "4     0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622   3.0  222.0   \n",
       "5     0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622   3.0  222.0   \n",
       "6     0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605   5.0  311.0   \n",
       "7     0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505   5.0  311.0   \n",
       "8     0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821   5.0  311.0   \n",
       "9     0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921   5.0  311.0   \n",
       "10    0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467   5.0  311.0   \n",
       "11    0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267   5.0  311.0   \n",
       "12    0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509   5.0  311.0   \n",
       "13    0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075   4.0  307.0   \n",
       "14    0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619   4.0  307.0   \n",
       "15    0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986   4.0  307.0   \n",
       "16    1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986   4.0  307.0   \n",
       "17    0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579   4.0  307.0   \n",
       "18    0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965   4.0  307.0   \n",
       "19    0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965   4.0  307.0   \n",
       "20    1.25179   0.0   8.14   0.0  0.538  5.570   98.1  3.7979   4.0  307.0   \n",
       "21    0.85204   0.0   8.14   0.0  0.538  5.965   89.2  4.0123   4.0  307.0   \n",
       "22    1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "23    0.98843   0.0   8.14   0.0  0.538  5.813  100.0  4.0952   4.0  307.0   \n",
       "24    0.75026   0.0   8.14   0.0  0.538  5.924   94.1  4.3996   4.0  307.0   \n",
       "25    0.84054   0.0   8.14   0.0  0.538  5.599   85.7  4.4546   4.0  307.0   \n",
       "26    0.67191   0.0   8.14   0.0  0.538  5.813   90.3  4.6820   4.0  307.0   \n",
       "27    0.95577   0.0   8.14   0.0  0.538  6.047   88.8  4.4534   4.0  307.0   \n",
       "28    0.77299   0.0   8.14   0.0  0.538  6.495   94.4  4.4547   4.0  307.0   \n",
       "29    1.00245   0.0   8.14   0.0  0.538  6.674   87.3  4.2390   4.0  307.0   \n",
       "..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n",
       "476   4.87141   0.0  18.10   0.0  0.614  6.484   93.6  2.3053  24.0  666.0   \n",
       "477  15.02340   0.0  18.10   0.0  0.614  5.304   97.3  2.1007  24.0  666.0   \n",
       "478  10.23300   0.0  18.10   0.0  0.614  6.185   96.7  2.1705  24.0  666.0   \n",
       "479  14.33370   0.0  18.10   0.0  0.614  6.229   88.0  1.9512  24.0  666.0   \n",
       "480   5.82401   0.0  18.10   0.0  0.532  6.242   64.7  3.4242  24.0  666.0   \n",
       "481   5.70818   0.0  18.10   0.0  0.532  6.750   74.9  3.3317  24.0  666.0   \n",
       "482   5.73116   0.0  18.10   0.0  0.532  7.061   77.0  3.4106  24.0  666.0   \n",
       "483   2.81838   0.0  18.10   0.0  0.532  5.762   40.3  4.0983  24.0  666.0   \n",
       "484   2.37857   0.0  18.10   0.0  0.583  5.871   41.9  3.7240  24.0  666.0   \n",
       "485   3.67367   0.0  18.10   0.0  0.583  6.312   51.9  3.9917  24.0  666.0   \n",
       "486   5.69175   0.0  18.10   0.0  0.583  6.114   79.8  3.5459  24.0  666.0   \n",
       "487   4.83567   0.0  18.10   0.0  0.583  5.905   53.2  3.1523  24.0  666.0   \n",
       "488   0.15086   0.0  27.74   0.0  0.609  5.454   92.7  1.8209   4.0  711.0   \n",
       "489   0.18337   0.0  27.74   0.0  0.609  5.414   98.3  1.7554   4.0  711.0   \n",
       "490   0.20746   0.0  27.74   0.0  0.609  5.093   98.0  1.8226   4.0  711.0   \n",
       "491   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
       "492   0.11132   0.0  27.74   0.0  0.609  5.983   83.5  2.1099   4.0  711.0   \n",
       "493   0.17331   0.0   9.69   0.0  0.585  5.707   54.0  2.3817   6.0  391.0   \n",
       "494   0.27957   0.0   9.69   0.0  0.585  5.926   42.6  2.3817   6.0  391.0   \n",
       "495   0.17899   0.0   9.69   0.0  0.585  5.670   28.8  2.7986   6.0  391.0   \n",
       "496   0.28960   0.0   9.69   0.0  0.585  5.390   72.9  2.7986   6.0  391.0   \n",
       "497   0.26838   0.0   9.69   0.0  0.585  5.794   70.6  2.8927   6.0  391.0   \n",
       "498   0.23912   0.0   9.69   0.0  0.585  6.019   65.3  2.4091   6.0  391.0   \n",
       "499   0.17783   0.0   9.69   0.0  0.585  5.569   73.5  2.3999   6.0  391.0   \n",
       "500   0.22438   0.0   9.69   0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n",
       "501   0.06263   0.0  11.93   0.0  0.573  6.593   69.1  2.4786   1.0  273.0   \n",
       "502   0.04527   0.0  11.93   0.0  0.573  6.120   76.7  2.2875   1.0  273.0   \n",
       "503   0.06076   0.0  11.93   0.0  0.573  6.976   91.0  2.1675   1.0  273.0   \n",
       "504   0.10959   0.0  11.93   0.0  0.573  6.794   89.3  2.3889   1.0  273.0   \n",
       "505   0.04741   0.0  11.93   0.0  0.573  6.030   80.8  2.5050   1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "5       18.7  394.12   5.21  \n",
       "6       15.2  395.60  12.43  \n",
       "7       15.2  396.90  19.15  \n",
       "8       15.2  386.63  29.93  \n",
       "9       15.2  386.71  17.10  \n",
       "10      15.2  392.52  20.45  \n",
       "11      15.2  396.90  13.27  \n",
       "12      15.2  390.50  15.71  \n",
       "13      21.0  396.90   8.26  \n",
       "14      21.0  380.02  10.26  \n",
       "15      21.0  395.62   8.47  \n",
       "16      21.0  386.85   6.58  \n",
       "17      21.0  386.75  14.67  \n",
       "18      21.0  288.99  11.69  \n",
       "19      21.0  390.95  11.28  \n",
       "20      21.0  376.57  21.02  \n",
       "21      21.0  392.53  13.83  \n",
       "22      21.0  396.90  18.72  \n",
       "23      21.0  394.54  19.88  \n",
       "24      21.0  394.33  16.30  \n",
       "25      21.0  303.42  16.51  \n",
       "26      21.0  376.88  14.81  \n",
       "27      21.0  306.38  17.28  \n",
       "28      21.0  387.94  12.80  \n",
       "29      21.0  380.23  11.98  \n",
       "..       ...     ...    ...  \n",
       "476     20.2  396.21  18.68  \n",
       "477     20.2  349.48  24.91  \n",
       "478     20.2  379.70  18.03  \n",
       "479     20.2  383.32  13.11  \n",
       "480     20.2  396.90  10.74  \n",
       "481     20.2  393.07   7.74  \n",
       "482     20.2  395.28   7.01  \n",
       "483     20.2  392.92  10.42  \n",
       "484     20.2  370.73  13.34  \n",
       "485     20.2  388.62  10.58  \n",
       "486     20.2  392.68  14.98  \n",
       "487     20.2  388.22  11.45  \n",
       "488     20.1  395.09  18.06  \n",
       "489     20.1  344.05  23.97  \n",
       "490     20.1  318.43  29.68  \n",
       "491     20.1  390.11  18.07  \n",
       "492     20.1  396.90  13.35  \n",
       "493     19.2  396.90  12.01  \n",
       "494     19.2  396.90  13.59  \n",
       "495     19.2  393.29  17.60  \n",
       "496     19.2  396.90  21.14  \n",
       "497     19.2  396.90  14.10  \n",
       "498     19.2  396.90  12.92  \n",
       "499     19.2  395.77  15.10  \n",
       "500     19.2  396.90  14.33  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "new_data= pd.DataFrame(dataset.data, columns=dataset.feature_names)[[\n",
    "    'CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT']]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dataset.data, columns=dataset.feature_names)[['CHAS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  PRICE  \n",
      "0     15.3  396.90   4.98   24.0  \n",
      "1     17.8  396.90   9.14   21.6  \n",
      "2     17.8  392.83   4.03   34.7  \n",
      "3     18.7  394.63   2.94   33.4  \n",
      "4     18.7  396.90   5.33   36.2  \n"
     ]
    }
   ],
   "source": [
    "new_data['PRICE'] = dataset.target\n",
    "print(new_data.head())\n",
    "Y = new_data['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 1)\n",
      "(167, 1)\n",
      "(339,)\n",
      "(167,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = sklearn.cross_validation.train_test_split(X, Y, test_size = 0.33, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCSp5gwCSaq5/wdOmxjkmCllNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1f41e4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lm.predict(X_test)\n",
    "\n",
    "plt.scatter(X, Y)\n",
    "plt.xlabel('CHAS')\n",
    "plt.ylabel(\"price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 22.4132911392\n",
      "coefficient: [ 6.00410017]\n"
     ]
    }
   ],
   "source": [
    "print(\"intercept:\",lm.intercept_)\n",
    "print(\"coefficient:\",lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 3-1\n",
    "- qualitative feature: CHAS(Charles River dummy variable)  \n",
    "- intercept is 22.4132911392 and coefficient is 6.00410017\n",
    "- We cannot categorize qualitative from the coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Problem #4. Regularization [30 points]  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-1. </h4> Answer the following questions \n",
    "\n",
    "- What is the objective using regularization?\n",
    "- Do you need to use regularization if you have only 1 feature (B0 and B1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 4-1\n",
    "- to solve the overfitting problem in statistical models\n",
    "- we don't need to use regularization if there is only 1 feature (B0 and B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-2.Ridge Regression </h4>  <br>\n",
    "In this part, you should download and analyze **\"Boston House Prices\"** dataset. <br>\n",
    "Use a code below to download the  dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow steps to answer questions.\n",
    "- Fit a linear regression model with all features and report the estimated coefficients for the fitted model (do not just print summary, make a table with feature names and estimated coefficients) \n",
    "-  Fit a ridge regression model with λ = 1. Report the estimated coefficients for the fitted model. \n",
    "-  Fit a ridge regression model with λ = 0. Report the estimated coefficients for the fitted model. \n",
    "- Compare estimated coefficients of ridge regression models with λ = 1 and λ = 0  and linear regression model. (you can use descriptive statistics)\n",
    "- What did you observe from this comparison? \n",
    "- Comment your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_name  coefficient\n",
      "0          CRIM     0.046422\n",
      "1            ZN    -0.019822\n",
      "2         INDUS     0.205146\n",
      "3          CHAS     3.831005\n",
      "4           NOX    -3.052409\n",
      "5            RM     2.368375\n",
      "6           AGE     0.012347\n",
      "7           DIS     0.329806\n",
      "8           RAD    -0.275650\n",
      "9           TAX     0.009898\n",
      "10      PTRATIO    -0.124019\n",
      "11            B    -0.002937\n",
      "12        LSTAT     0.109801\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "regr = linear_model.LinearRegression(copy_X=True,fit_intercept=True,n_jobs=1,normalize=False)\n",
    "regr.fit(X_train,Y_train)\n",
    "prediction = regr.predict(X_test)\n",
    "coef = pd.DataFrame(dataset.feature_names,columns=['feature_name'])\n",
    "coef['coefficient'] = regr.coef_\n",
    "print(coef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_names  coefficient_1.0\n",
      "0           CRIM         0.047039\n",
      "1             ZN        -0.019388\n",
      "2          INDUS         0.199105\n",
      "3           CHAS         3.650468\n",
      "4            NOX        -1.512977\n",
      "5             RM         2.355168\n",
      "6            AGE         0.011229\n",
      "7            DIS         0.348437\n",
      "8            RAD        -0.276841\n",
      "9            TAX         0.009668\n",
      "10       PTRATIO        -0.109104\n",
      "11             B        -0.002860\n",
      "12         LSTAT         0.104123\n"
     ]
    }
   ],
   "source": [
    "regr_ridge1 = Ridge(alpha=1.0)\n",
    "regr_ridge1.fit(X_train,Y_train)\n",
    "prediction_ridge1 = regr_ridge1.predict(X_test)\n",
    "coef_ridge1 = pd.DataFrame(dataset.feature_names,columns=['feature_names'])\n",
    "coef_ridge1['coefficient_1.0'] = regr_ridge1.coef_\n",
    "print(coef_ridge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_names  coefficient_0.0\n",
      "0           CRIM         0.046422\n",
      "1             ZN        -0.019822\n",
      "2          INDUS         0.205146\n",
      "3           CHAS         3.831005\n",
      "4            NOX        -3.052409\n",
      "5             RM         2.368375\n",
      "6            AGE         0.012347\n",
      "7            DIS         0.329806\n",
      "8            RAD        -0.275650\n",
      "9            TAX         0.009898\n",
      "10       PTRATIO        -0.124019\n",
      "11             B        -0.002937\n",
      "12         LSTAT         0.109801\n"
     ]
    }
   ],
   "source": [
    "regr_ridge0 = Ridge(alpha=0.0)\n",
    "regr_ridge0.fit(X_train,Y_train)\n",
    "prediction_ridge0 = regr_ridge0.predict(X_test)\n",
    "coef_ridge0 = pd.DataFrame(dataset.feature_names,columns=['feature_names'])\n",
    "coef_ridge0['coefficient_0.0'] = regr_ridge0.coef_\n",
    "print(coef_ridge0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_names  coefficient_1.0  coefficient_0.0\n",
      "0           CRIM         0.047039         0.046422\n",
      "1             ZN        -0.019388        -0.019822\n",
      "2          INDUS         0.199105         0.205146\n",
      "3           CHAS         3.650468         3.831005\n",
      "4            NOX        -1.512977        -3.052409\n",
      "5             RM         2.355168         2.368375\n",
      "6            AGE         0.011229         0.012347\n",
      "7            DIS         0.348437         0.329806\n",
      "8            RAD        -0.276841        -0.275650\n",
      "9            TAX         0.009668         0.009898\n",
      "10       PTRATIO        -0.109104        -0.124019\n",
      "11             B        -0.002860        -0.002937\n",
      "12         LSTAT         0.104123         0.109801\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient_1.0</th>\n",
       "      <th>coefficient_0.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.369544</td>\n",
       "      <td>0.264459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.279641</td>\n",
       "      <td>1.553246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.512977</td>\n",
       "      <td>-3.052409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.019388</td>\n",
       "      <td>-0.019822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.011229</td>\n",
       "      <td>0.012347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.199105</td>\n",
       "      <td>0.205146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.650468</td>\n",
       "      <td>3.831005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefficient_1.0  coefficient_0.0\n",
       "count        13.000000        13.000000\n",
       "mean          0.369544         0.264459\n",
       "std           1.279641         1.553246\n",
       "min          -1.512977        -3.052409\n",
       "25%          -0.019388        -0.019822\n",
       "50%           0.011229         0.012347\n",
       "75%           0.199105         0.205146\n",
       "max           3.650468         3.831005"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_comb = pd.merge(coef_ridge1,coef_ridge0)\n",
    "print(coef_comb)\n",
    "coef_comb.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 4-2  \n",
    "Compare estimated coefficients of ridge regression models with λ = 1 and λ = 0 and linear regression model, they are simiar, but with larger alpha, results in stronger regularizatiom. it is same as linear regression without ridge regularization with alpha is equal to 0.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-3.Ridge Regression (part 2) </h4>  <br>\n",
    "Fit a ridge regression with λ = 5, 10, 50, 100, and 1000. For each value, report the estimated coefficients for the fitted model (do not just print summary, make a DataFrame with feature names and estimated coefficients)\n",
    "- What happens to the coefficients as you increase λ?\n",
    "- What happens to the flexibility of the model as you increase λ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_names  coefficient_x  coefficient_y  coefficient_x  coefficient_y  \\\n",
      "0           CRIM       0.045604       0.043616       0.035714       0.031684   \n",
      "1             ZN      -0.018272      -0.017185      -0.012099      -0.008827   \n",
      "2          INDUS       0.196330       0.196149       0.189719       0.181245   \n",
      "3           CHAS       3.104396       2.621852       1.179522       0.703179   \n",
      "4            NOX      -0.494478      -0.266445      -0.058339      -0.030488   \n",
      "5             RM       2.275852       2.175899       1.584241       1.175807   \n",
      "6            AGE       0.011180       0.011850       0.015487       0.017535   \n",
      "7            DIS       0.348028       0.335240       0.262223       0.212655   \n",
      "8            RAD      -0.270213      -0.261836      -0.227260      -0.209227   \n",
      "9            TAX       0.009233       0.008877       0.007579       0.006921   \n",
      "10       PTRATIO      -0.106916      -0.113618      -0.146541      -0.160078   \n",
      "11             B      -0.002722      -0.002630      -0.002523      -0.002605   \n",
      "12         LSTAT       0.092552       0.081930       0.032752       0.003309   \n",
      "\n",
      "    coefficient  \n",
      "0      0.016885  \n",
      "1      0.001764  \n",
      "2      0.140414  \n",
      "3      0.086696  \n",
      "4     -0.002504  \n",
      "5      0.208764  \n",
      "6      0.021820  \n",
      "7      0.046282  \n",
      "8     -0.153608  \n",
      "9      0.004624  \n",
      "10    -0.118932  \n",
      "11    -0.002943  \n",
      "12    -0.056467  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient_x</th>\n",
       "      <th>coefficient_y</th>\n",
       "      <th>coefficient_x</th>\n",
       "      <th>coefficient_y</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.399275</td>\n",
       "      <td>0.370285</td>\n",
       "      <td>0.220037</td>\n",
       "      <td>0.147778</td>\n",
       "      <td>0.014830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.050561</td>\n",
       "      <td>0.919178</td>\n",
       "      <td>0.536638</td>\n",
       "      <td>0.381111</td>\n",
       "      <td>0.096534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.494478</td>\n",
       "      <td>-0.266445</td>\n",
       "      <td>-0.227260</td>\n",
       "      <td>-0.209227</td>\n",
       "      <td>-0.153608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.018272</td>\n",
       "      <td>-0.017185</td>\n",
       "      <td>-0.012099</td>\n",
       "      <td>-0.008827</td>\n",
       "      <td>-0.002943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.011180</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>0.015487</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>0.004624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.196330</td>\n",
       "      <td>0.196149</td>\n",
       "      <td>0.189719</td>\n",
       "      <td>0.181245</td>\n",
       "      <td>0.046282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.104396</td>\n",
       "      <td>2.621852</td>\n",
       "      <td>1.584241</td>\n",
       "      <td>1.175807</td>\n",
       "      <td>0.208764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefficient_x  coefficient_y  coefficient_x  coefficient_y  coefficient\n",
       "count      13.000000      13.000000      13.000000      13.000000    13.000000\n",
       "mean        0.399275       0.370285       0.220037       0.147778     0.014830\n",
       "std         1.050561       0.919178       0.536638       0.381111     0.096534\n",
       "min        -0.494478      -0.266445      -0.227260      -0.209227    -0.153608\n",
       "25%        -0.018272      -0.017185      -0.012099      -0.008827    -0.002943\n",
       "50%         0.011180       0.011850       0.015487       0.006921     0.004624\n",
       "75%         0.196330       0.196149       0.189719       0.181245     0.046282\n",
       "max         3.104396       2.621852       1.584241       1.175807     0.208764"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "alphas = [5,10,50,100,1000]\n",
    "coef_ridge_final = pd.DataFrame(dataset.feature_names,columns=['feature_names'])\n",
    "for alpha in range(len(alphas)):\n",
    "    regr_ridge = linear_model.Ridge(alpha=alphas[alpha])\n",
    "    regr_ridge.fit(X_train,Y_train)\n",
    "    coef_ridge = pd.DataFrame(dataset.feature_names,columns=['feature_names'])\n",
    "    coef_ridge['coefficient'] = regr_ridge.coef_\n",
    "    coef_ridge_final = pd.merge(coef_ridge_final,coef_ridge,how='left',on=['feature_names'])\n",
    "    \n",
    "print(coef_ridge_final)\n",
    "coef_ridge_final.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 4-3\n",
    "with the increase of alpha, coefficients keep getting close to 0, the flexibility is decreasing, the model is more closer to linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-4 Lasso Regression </h4>  <br>\n",
    "In this part, you should download and analyze **\"Boston House Prices\"** dataset. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow steps to answer questions.\n",
    "- Fit a linear regression model with all features and report the estimated coefficients for the fitted model (do not just print summary, make a DataFrame with feature names and estimated coefficients) \n",
    "-  Fit a lasso regression model with λ = 1. Report the estimated coefficients for the fitted model. \n",
    "-  Fit a lasso regression model with λ = 0. Report the estimated coefficients for the fitted model. \n",
    "- Compare estimated coefficients of lasso regression models with λ = 1 and λ = 0, ridge regression models with λ = 1 and λ = 0 and linear regression model. (you can use descriptive statistics)\n",
    "\n",
    "- What did you observe from this comparison? \n",
    "\n",
    "- Comment your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_names  coefficient_1.0\n",
      "0           CRIM         0.000000\n",
      "1             ZN         0.003145\n",
      "2          INDUS         0.102677\n",
      "3           CHAS         0.000000\n",
      "4            NOX        -0.000000\n",
      "5             RM         0.000000\n",
      "6            AGE         0.020522\n",
      "7            DIS         0.000000\n",
      "8            RAD        -0.114364\n",
      "9            TAX         0.002777\n",
      "10       PTRATIO        -0.000000\n",
      "11             B        -0.002812\n",
      "12         LSTAT        -0.040331\n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "regr_lasso1 = Lasso(alpha=1.0)\n",
    "regr_lasso1.fit(X_train,Y_train)\n",
    "prediction_lasso1 = regr_lasso1.predict(X_test)\n",
    "coef_lasso1 = pd.DataFrame(dataset.feature_names,columns=['feature_names'])\n",
    "coef_lasso1['coefficient_1.0'] = regr_lasso1.coef_\n",
    "print(coef_lasso1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_names  coefficient_0\n",
      "0           CRIM       0.046422\n",
      "1             ZN      -0.019822\n",
      "2          INDUS       0.205146\n",
      "3           CHAS       3.831005\n",
      "4            NOX      -3.052409\n",
      "5             RM       2.368375\n",
      "6            AGE       0.012347\n",
      "7            DIS       0.329806\n",
      "8            RAD      -0.275650\n",
      "9            TAX       0.009898\n",
      "10       PTRATIO      -0.124019\n",
      "11             B      -0.002937\n",
      "12         LSTAT       0.109801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyy7645/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "/Users/cyy7645/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/cyy7645/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "regr_lasso0 = Lasso(alpha = 0.0)\n",
    "regr_lasso0.fit(X_train,Y_train)\n",
    "coef_lasso0 = pd.DataFrame(dataset.feature_names,columns=['feature_names'])\n",
    "coef_lasso0['coefficient_0'] = regr_lasso0.coef_\n",
    "print(coef_lasso0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_names  coefficient_0  coefficient_1.0\n",
      "0           CRIM       0.046422         0.000000\n",
      "1             ZN      -0.019822         0.003145\n",
      "2          INDUS       0.205146         0.102677\n",
      "3           CHAS       3.831005         0.000000\n",
      "4            NOX      -3.052409        -0.000000\n",
      "5             RM       2.368375         0.000000\n",
      "6            AGE       0.012347         0.020522\n",
      "7            DIS       0.329806         0.000000\n",
      "8            RAD      -0.275650        -0.114364\n",
      "9            TAX       0.009898         0.002777\n",
      "10       PTRATIO      -0.124019        -0.000000\n",
      "11             B      -0.002937        -0.002812\n",
      "12         LSTAT       0.109801        -0.040331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient_0</th>\n",
       "      <th>coefficient_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.264459</td>\n",
       "      <td>-0.002184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.553246</td>\n",
       "      <td>0.046218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.052409</td>\n",
       "      <td>-0.114364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.019822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.205146</td>\n",
       "      <td>0.002777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.831005</td>\n",
       "      <td>0.102677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefficient_0  coefficient_1.0\n",
       "count      13.000000        13.000000\n",
       "mean        0.264459        -0.002184\n",
       "std         1.553246         0.046218\n",
       "min        -3.052409        -0.114364\n",
       "25%        -0.019822         0.000000\n",
       "50%         0.012347         0.000000\n",
       "75%         0.205146         0.002777\n",
       "max         3.831005         0.102677"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_combined = pd.merge(coef_lasso0,coef_lasso1)\n",
    "print(coef_combined)\n",
    "coef_combined.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 4-4\n",
    "with alpha = 1.0, 11 weights of features becomes 0, which means regularization works, while with alpha = 0.0, it results in same result without regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #4-5.Lasso Regression (part 2) </h4>  <br>\n",
    "Fit a lasso regression with λ = 5, 10, 50, 100, and 1000. For each value, report the estimated coefficients for the fitted model (do not just print summary, make a DataFrmae with feature names and estimated coefficients)\n",
    "- What happens to the coefficients as you increase λ?\n",
    "- What happens to the flexibility of the model as you increase λ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_names  coefficient  coefficient_x  coefficient_y  coefficient_x  \\\n",
      "0           CRIM          0.0            0.0            0.0      -0.000000   \n",
      "1             ZN         -0.0           -0.0           -0.0      -0.000000   \n",
      "2          INDUS          0.0            0.0            0.0       0.000000   \n",
      "3           CHAS          0.0            0.0            0.0       0.000000   \n",
      "4            NOX          0.0            0.0            0.0       0.000000   \n",
      "5             RM          0.0            0.0            0.0       0.000000   \n",
      "6            AGE          0.0            0.0            0.0       0.012129   \n",
      "7            DIS         -0.0           -0.0           -0.0      -0.000000   \n",
      "8            RAD         -0.0           -0.0           -0.0      -0.000000   \n",
      "9            TAX          0.0            0.0            0.0       0.000000   \n",
      "10       PTRATIO         -0.0           -0.0           -0.0      -0.000000   \n",
      "11             B         -0.0           -0.0           -0.0      -0.001377   \n",
      "12         LSTAT          0.0            0.0            0.0      -0.000000   \n",
      "\n",
      "    coefficient_y  \n",
      "0       -0.000000  \n",
      "1       -0.000000  \n",
      "2        0.000000  \n",
      "3        0.000000  \n",
      "4        0.000000  \n",
      "5        0.000000  \n",
      "6        0.018559  \n",
      "7       -0.000000  \n",
      "8       -0.000000  \n",
      "9       -0.000054  \n",
      "10      -0.000000  \n",
      "11      -0.001554  \n",
      "12      -0.000000  \n"
     ]
    }
   ],
   "source": [
    "#Write your narrative answer here\n",
    "alphas = [5,10,50,100,1000]\n",
    "coef_lasso_final = pd.DataFrame(dataset.feature_names,columns=['feature_names'])\n",
    "for alpha in range(len(alphas)):\n",
    "    regr_lasso = Lasso(alpha = alphas[alpha])\n",
    "    regr_lasso.fit(X_train,Y_train)\n",
    "    coef_lasso['coefficient'] = regr_lasso.coef_\n",
    "    coef_lasso_final = pd.merge(coef_lasso,coef_lasso_final,how='left',on='feature_names')\n",
    "print(coef_lasso_final)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 4-5\n",
    "with the increase of alpha, the coefficients shrink to zero. the model is getting close to linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>  Problem #5.Logistic Regression [30 points] </h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #5-1. </h4>  <br>\n",
    "We fit a logistic regression model to predict the probability that an individual will default on his/her credit card balance. We used the total balance (single feature) to fit the model and got the results shown in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|        |Coefficient| Std.error|Z -statistic|P-Value|\n",
    "|:--:|:-------------------------------:|\n",
    "|Intercept|-10.6513|0.3612|-29.5|<0.0001|\n",
    "|balance|0.0055|0.002|24.9|<0.0001|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the parametric model used in logistic regression?\n",
    "- What is the probability that an individual with a balance equal to 15000 dollar will default?\n",
    "- What is the probability that an individual with balance equals to 800 dollar will not default?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0019242363522599308\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "p1 = math.exp(-10.6513+0.0055*15000)/(1 + math.exp(-10.6513+0.0055*15000))\n",
    "print(p1)\n",
    "p2 = math.exp(-10.6513+0.0055*800)/(1 + math.exp(-10.6513+0.0055*800))\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## answer 5-1\n",
    "- math.exp(-10.6513+0.0055X)/(1 + math.exp(-10.6513+0.0055X))  \n",
    "- with the balance of 15000, the person will not default on his/her credit card balance. while with the balance of 800, the person will default on his/her credit card balance at high possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Problem #5-2. </h4>  <br>\n",
    "\n",
    "The coefficients of logistic regression are obtained by maximizing the likelihood function\n",
    "\n",
    "\\begin{array} \\\\\n",
    "l(\\beta) = \\prod_{i:y_{i}=1} P(y_{i} = 1|x)\\prod_{i{}':y_{{i}'}=0} (1-P(y_{{i}'} = 1|x))\n",
    "\\end{array}\n",
    "Show that maximizing the\n",
    "likelihood function is equivalent to minimizing the cost function $J(\\beta)$, such that.\n",
    "\\begin{array} \\\\\n",
    "J(\\beta) = -\\sum [y_{i} log(P(y_{i} = 1|x)) + (1- y_{i})log(1- P(y_{i} = 1|x))]\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "Here $n$ is the number training examples. Mention one possible method for obtaining the\n",
    "optimal coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use batch gradient descent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
